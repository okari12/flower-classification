import numpy as np
import os
from joblib import load
from skimage import io, color, feature
from skimage.transform import resize, rotate
import scipy.io as sio

# --- 1. å®šä¹‰æ–‡ä»¶è·¯å¾„ (å¿…é¡»ä¸ä¿å­˜æ—¶ä¸€è‡´) ---
MODEL_PATH = 'best_flower_model.joblib'
SCALER_PATH = 'scaler.joblib'
# ğŸ’¡ ç¤ºä¾‹ï¼šè¦é¢„æµ‹çš„æ–°å›¾ç‰‡è·¯å¾„
NEW_IMAGE_PATH = './jpg/image_00001.jpg'  # å‡è®¾ç”¨æ‚¨æ•°æ®é›†ä¸­çš„ç¬¬ä¸€å¼ å›¾ç‰‡æµ‹è¯•

# --- 2. åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨ ---
try:
    best_rf_model = load(MODEL_PATH)
    scaler = load(SCALER_PATH)
    print("æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸã€‚")
except FileNotFoundError:
    print(f"é”™è¯¯ï¼šæœªèƒ½æ‰¾åˆ°æ¨¡å‹æˆ–æ ‡å‡†åŒ–å™¨æ–‡ä»¶ã€‚è¯·ç¡®ä¿ {MODEL_PATH} å’Œ {SCALER_PATH} å­˜åœ¨ã€‚")
    exit()


# --- 3. å®šä¹‰ç‰¹å¾æå–å‡½æ•° (å¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒ) ---

def extract_features(image_path, bins=(8, 8, 8), radius=3, n_points=24):
    """
    æå–é¢œè‰²ç›´æ–¹å›¾ï¼ˆHSVï¼‰å’ŒLBPçº¹ç†ç‰¹å¾ (ä¸è®­ç»ƒæ—¶ç›¸åŒ)ã€‚
    """
    try:
        image = io.imread(image_path)
        image_gray = color.rgb2gray(image)
        image_resized = resize(image_gray, (128, 128))

        # é¢œè‰²ç‰¹å¾
        image_hsv = color.rgb2hsv(image)
        hist, _ = np.histogramdd(
            image_hsv.reshape(-1, 3), bins=bins, range=[(0, 1), (0, 1), (0, 1)], density=True
        )
        color_features = hist.flatten()

        # çº¹ç†ç‰¹å¾
        lbp = feature.local_binary_pattern(
            (image_resized * 255).astype(np.uint8), n_points, radius, method="uniform"
        )
        (hist_lbp, _) = np.histogram(
            lbp.ravel(), bins=np.arange(0, n_points + 2), range=(0, n_points + 1)
        )
        hist_lbp = hist_lbp.astype("float")
        hist_lbp /= (hist_lbp.sum() + 1e-7)
        texture_features = hist_lbp

        return np.hstack([color_features, texture_features])
    except Exception as e:
        print(f"å›¾ç‰‡ç‰¹å¾æå–å¤±è´¥: {e}")
        return None


# --- 4. é¢„æµ‹å‡½æ•° ---

def predict_single_image(image_path, model, scaler):
    """
    å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œç‰¹å¾æå–ã€æ ‡å‡†åŒ–å’Œé¢„æµ‹ã€‚
    """
    if not os.path.exists(image_path):
        print(f"é”™è¯¯ï¼šå›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°: {image_path}")
        return None, None

    # 1. ç‰¹å¾æå–
    raw_features = extract_features(image_path)
    if raw_features is None:
        return None, None

    # 2. è½¬æ¢æˆ 2D æ•°ç»„ (1 æ ·æœ¬, N ç‰¹å¾)
    # Scikit-learn æ¨¡å‹è¦æ±‚è¾“å…¥å¿…é¡»æ˜¯äºŒç»´æ•°ç»„
    features_2d = raw_features.reshape(1, -1)

    # 3. æ ‡å‡†åŒ– (ä½¿ç”¨è®­ç»ƒæ—¶çš„ Scaler)
    scaled_features = scaler.transform(features_2d)

    # 4. é¢„æµ‹ç±»åˆ« (è¿”å› 0 åˆ° 101 çš„æ•´æ•°)
    prediction_index = model.predict(scaled_features)[0]

    # 5. é¢„æµ‹æ¦‚ç‡ (å¯é€‰ï¼Œç”¨äºç½®ä¿¡åº¦)
    probabilities = model.predict_proba(scaled_features)[0]
    confidence = np.max(probabilities)

    return prediction_index, confidence


def extract_features_from_array(image, bins=(8, 8, 8), radius=3, n_points=24):
    """è·Ÿè®­ç»ƒæ—¶ç›¸åŒçš„ç‰¹å¾æå–é€»è¾‘ï¼Œä½†æ¥å— numpy ndarray è€Œéæ–‡ä»¶è·¯å¾„ã€‚"""
    try:
        if image.ndim == 2:
            image_gray = image
        else:
            image_gray = color.rgb2gray(image)
        image_resized = resize(image_gray, (128, 128))

        if image.ndim == 2:
            image_rgb = np.stack([image, image, image], axis=-1)
        else:
            image_rgb = image
        image_hsv = color.rgb2hsv(image_rgb)
        hist, _ = np.histogramdd(
            image_hsv.reshape(-1, 3), bins=bins, range=[(0, 1), (0, 1), (0, 1)], density=True
        )
        color_features = hist.flatten()

        lbp = feature.local_binary_pattern(
            (image_resized * 255).astype(np.uint8), n_points, radius, method="uniform"
        )
        (hist_lbp, _) = np.histogram(
            lbp.ravel(), bins=np.arange(0, n_points + 2), range=(0, n_points + 1)
        )
        hist_lbp = hist_lbp.astype("float")
        hist_lbp /= (hist_lbp.sum() + 1e-7)
        texture_features = hist_lbp

        return np.hstack([color_features, texture_features])
    except Exception as e:
        print(f"å›¾ç‰‡æ•°ç»„ç‰¹å¾æå–å¤±è´¥: {e}")
        return None


def _augment_images_from_array(img_arr):
    """è¿”å›å¢å¼ºåçš„ numpy å›¾åƒåˆ—è¡¨ï¼ˆåŒ…æ‹¬åŸå›¾ï¼‰ã€‚
    ä¸€äº›å¢å¼ºï¼šåŸå§‹ã€æ°´å¹³ç¿»è½¬ã€æ—‹è½¬ Â±15/Â±30ã€äº®åº¦ç¼©æ”¾ 0.9/1.1
    """
    augs = []
    try:
        # Ensure dtype is suitable for skimage functions
        arr = img_arr
        augs.append(arr)
        # æ°´å¹³ç¿»è½¬
        try:
            augs.append(np.fliplr(arr))
        except Exception:
            pass
        # æ—‹è½¬ï¼ˆpreserve_range ä¿æŒæ•°å€¼èŒƒå›´ï¼‰
        for angle in (15, -15):
            try:
                r = rotate(arr, angle, preserve_range=True).astype(arr.dtype)
                augs.append(r)
            except Exception:
                pass
    except Exception as e:
        print(f"ç”Ÿæˆå¢å¼ºå›¾å¤±è´¥: {e}")
    return augs


def tta_average_probabilities(image_path, model, scaler, n_augs=None):
    """å¯¹å•å¼ å›¾ç‰‡æ‰§è¡Œ TTA å¹¶è¿”å›å¹³å‡æ¦‚ç‡å‘é‡ã€‚
    - image_path: æ–‡ä»¶è·¯å¾„
    - model: å·²åŠ è½½åˆ†ç±»å™¨ï¼ˆéœ€æ”¯æŒ predict_probaï¼‰
    - scaler: æ ‡å‡†åŒ–å™¨
    - n_augs: é™åˆ¶å¢å¼ºæ•°é‡ï¼ˆNone åˆ™å…¨éƒ¨ï¼‰
    è¿”å›: avg_probs (1D numpy array) æˆ– None
    """
    try:
        img = io.imread(image_path)
    except Exception as e:
        print(f"è¯»å–å›¾ç‰‡å¤±è´¥ï¼ˆTTAï¼‰: {e}")
        return None

    aug_imgs = _augment_images_from_array(img)
    if n_augs is not None:
        aug_imgs = aug_imgs[:n_augs]

    all_probs = []
    for arr in aug_imgs:
        feats = extract_features_from_array(arr)
        if feats is None:
            continue
        feats_2d = feats.reshape(1, -1)
        try:
            scaled = scaler.transform(feats_2d)
            probs = model.predict_proba(scaled)[0]
            all_probs.append(probs)
        except Exception as e:
            print(f"TTA é¢„æµ‹å¤±è´¥ï¼ˆå•å¢å¼ºï¼‰: {e}")
            continue

    if not all_probs:
        return None

    avg_probs = np.mean(all_probs, axis=0)
    return avg_probs


def get_probs_single(image_path, model, scaler):
    """å¯¹å•å¼ å›¾ç‰‡è®¡ç®— predict_probaï¼Œè¿”å›æ¦‚ç‡å‘é‡æˆ– Noneã€‚"""
    if not os.path.exists(image_path):
        print(f"é”™è¯¯ï¼šå›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°: {image_path}")
        return None
    feats = extract_features(image_path)
    if feats is None:
        return None
    feats_2d = feats.reshape(1, -1)
    try:
        scaled = scaler.transform(feats_2d)
        probs = model.predict_proba(scaled)[0]
        return probs
    except Exception as e:
        print(f"è®¡ç®—å•å¼ æ¦‚ç‡å¤±è´¥: {e}")
        return None


# --- 5. æ‰§è¡Œé¢„æµ‹ ---
USE_TTA = True
TOP_K = 5

print(f"\nå¼€å§‹é¢„æµ‹å›¾ç‰‡: {NEW_IMAGE_PATH}")

if USE_TTA:
    print("ä½¿ç”¨ TTA (æµ‹è¯•æ—¶å¢å¼º) æ¨¡å¼è¿›è¡Œé¢„æµ‹...")
    probs = tta_average_probabilities(NEW_IMAGE_PATH, best_rf_model, scaler)
else:
    print("ä½¿ç”¨æ ‡å‡†æ¨¡å¼è¿›è¡Œé¢„æµ‹...")
    probs = get_probs_single(NEW_IMAGE_PATH, best_rf_model, scaler)

if probs is None:
    print("æœªèƒ½è·å¾—é¢„æµ‹æ¦‚ç‡ï¼Œé¢„æµ‹å¤±è´¥ã€‚")
else:
    topk_idx = np.argsort(-probs)[:TOP_K]
    print(f"\n--- Top-{TOP_K} å€™é€‰ ---")
    for rank, idx in enumerate(topk_idx, start=1):
        prob = probs[idx]
        print(f"{rank}. ç±»åˆ«ç´¢å¼•(0-based): {idx}, å®é™…ç±»åˆ«(1-based): {idx + 1}, æ¦‚ç‡: {prob * 100:.2f}%")

    top1_idx = topk_idx[0]
    print(f"\n--- æœ€ç»ˆ Top-1 é¢„æµ‹ ---")
    print(f"é¢„æµ‹çš„ç±»åˆ«ç´¢å¼• (0-based): {top1_idx}")
    print(f"å¯¹åº”çš„å®é™…ç±»åˆ« (1-based): {top1_idx + 1}")
    print(f"é¢„æµ‹ç½®ä¿¡åº¦: {probs[top1_idx] * 100:.2f}%")
